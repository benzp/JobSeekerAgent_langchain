{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","#drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/ColabNotebooks/\n","%pwd\n","%ls -d */\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WsIsu9WuYH8s","outputId":"5b6da50a-78ff-4d9e-f7e2-b81d856f4ee1","executionInfo":{"status":"ok","timestamp":1765458673701,"user_tz":-330,"elapsed":116,"user":{"displayName":"Benz Paul","userId":"09389317512058025402"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks\n"," \u001b[0m\u001b[01;34mJobSeekerAgent_langchain/\u001b[0m/  \u001b[01;34m'Sample Files/'\u001b[0m/\n","/content/drive/MyDrive/ColabNotebooks/JobSeekerAgent_langchain\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/benzp/JobSeekerAgent_langchain.git\n","\n","%pwd\n","%cd JobSeekerAgent_langchain"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XiY-QxFm5AvP","outputId":"cf07910e-abe9-44b9-99b0-011248e5fa46","executionInfo":{"status":"ok","timestamp":1765459099035,"user_tz":-330,"elapsed":124,"user":{"displayName":"Benz Paul","userId":"09389317512058025402"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'JobSeekerAgent_langchain' already exists and is not an empty directory.\n","/content/drive/MyDrive/ColabNotebooks/JobSeekerAgent_langchain\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9gTdsgvq26n","outputId":"3a78b1d1-8573-479a-ae17-805e5e50b161","executionInfo":{"status":"ok","timestamp":1765459180083,"user_tz":-330,"elapsed":6348,"user":{"displayName":"Benz Paul","userId":"09389317512058025402"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.52.1)\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.2)\n","Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.1)\n","Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n","Requirement already satisfied: langchain-tavily in /usr/local/lib/python3.12/dist-packages (0.2.13)\n","Requirement already satisfied: python-docx in /usr/local/lib/python3.12/dist-packages (1.2.0)\n","Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.5)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n","Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.1.1)\n","Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n","Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.9.0)\n","Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n","Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n","Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n","Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n","Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.55)\n","Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n","Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n","Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.12.0)\n","Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n","Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n","Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.12)\n","Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n","Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"]}],"source":["!pip install streamlit pyngrok langchain langchain-openai langchain-community langchain-tavily python-docx\n"]},{"cell_type":"code","source":["%pwd\n","%ls -la\n","from google.colab import userdata\n","import os\n","\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n","os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GETKXnIff37W","executionInfo":{"status":"ok","timestamp":1765461346609,"user_tz":-330,"elapsed":3158,"user":{"displayName":"Benz Paul","userId":"09389317512058025402"}},"outputId":"774fccff-fbe9-445a-a153-8f65a49afdc7"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["total 55\n","-rw------- 1 root root  1454 Dec 11 13:47  app.py\n","drwx------ 8 root root  4096 Dec 11 12:32  \u001b[0m\u001b[01;34m.git\u001b[0m/\n","-rw------- 1 root root 27649 Dec 11 13:52  JobSeekerAgent.ipynb\n","-rw------- 1 root root  2788 Dec 11 13:46  jobseeker_utils.py\n","drwx------ 2 root root  4096 Dec 11 13:47  \u001b[01;34m__pycache__\u001b[0m/\n","-rw------- 1 root root    73 Dec 11 12:32  README.md\n","-rw------- 1 root root 14419 Dec 11 12:32 'Sample Benz Resume.docx'\n"]}]},{"cell_type":"code","source":["%%writefile app.py\n","# paste the entire streamlit UI code here\n","from tempfile import NamedTemporaryFile\n","\n","import os\n","\n","import streamlit as st\n","import jobseeker_utils\n","\n","# =========================\n","# Streamlit Page Config\n","# =========================\n","\n","st.set_page_config(\n","    page_title=\"AI Job Assistant\",\n","    layout=\"wide\",\n",")\n","\n","st.title(\"AI Job Search & Resume Assistant\")\n","\n","st.write(\n","    \"\"\"\n","Provide your **current skills/experience** (via resume upload). And provide your ***aspirational role*** (via text input).\n","\"\"\"\n",")\n","\n","st.subheader(\"2️⃣ Current Skills & Experience\")\n","resume = st.file_uploader(\"Upload your current resume (.pdf, .docx, .txt):\")\n","\n","st.subheader(\"3️⃣ Aspirational Role\")\n","aspirational_role = st.text_area(\"Enter the aspirational role(s) you want to apply for:\")\n","\n","submitted = st.button(\"Search Ideal Jobs\")\n","\n","if submitted:\n","    # Show what the user provided\n","    st.write(\"Submitted!\")\n","    if aspirational_role:\n","        st.write(\"Aspirational role:\", aspirational_role)\n","    else:\n","        st.write(\"No aspirational role entered.\")\n","    if resume is not None:\n","        st.write(\"Uploaded Resume File name:\", resume.name)\n","        resume_contents = jobseeker_utils.extract_text_from_file(resume)\n","        st.write(\"Resume Contents:\", resume_contents)\n","        st.subheader(\"Matched Search Job Results\")\n","\n","        final_output = jobseeker_utils.TopMatchingJobs(aspirational_role, resume_contents)\n","        st.write(final_output)\n","    else:\n","        st.write(\"No resume uploaded.\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t2TiQYrBrXAy","outputId":"8161c6aa-9688-4465-a7d0-bb5167fd2dfa","executionInfo":{"status":"ok","timestamp":1765462002593,"user_tz":-330,"elapsed":8,"user":{"displayName":"Benz Paul","userId":"09389317512058025402"}}},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","source":["!pkill -f \"streamlit run app.py\" || echo \"no old streamlit\"\n","\n","# Start Streamlit fully detached\n","!nohup streamlit run app.py --server.port 8501 --server.headless true > /tmp/streamlit.log 2>&1 &\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6cMOF6Zlo-SA","outputId":"81dcd9c9-cd6d-4dde-b84f-5b0a1c0f7a3a","executionInfo":{"status":"ok","timestamp":1765459396223,"user_tz":-330,"elapsed":295,"user":{"displayName":"Benz Paul","userId":"09389317512058025402"}}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["^C\n"]}]},{"cell_type":"code","source":["from pyngrok import ngrok\n","\n","ngrok.kill()\n","\n","ngrok.set_auth_token('36f8VolnFP2Ilo6ufMvTfNijTx8_2GfmfdoiDoAZkK4KsuLVA')\n","\n","public_url = ngrok.connect('8501')\n","public_url"],"metadata":{"id":"xM4syBm92tyr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"11af61f6-770e-4ebd-9bf0-7b136fa5e611","executionInfo":{"status":"ok","timestamp":1765459402585,"user_tz":-330,"elapsed":1341,"user":{"displayName":"Benz Paul","userId":"09389317512058025402"}}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":[]},{"output_type":"execute_result","data":{"text/plain":["<NgrokTunnel: \"https://luciana-unsurprised-kristi.ngrok-free.dev\" -> \"http://localhost:8501\">"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["%%writefile jobseeker_utils.py\n","import os\n","import json\n","from langchain_openai import ChatOpenAI\n","from langchain_tavily import TavilySearch\n","from langchain.tools import tool        # decorator to wrap Python functions as tools\n","from langchain.agents import create_agent\n","from tempfile import NamedTemporaryFile\n","from docx import Document\n","\n","\n","\n","def TopMatchingJobs(aspirations: str, current_skills: str) -> str:\n","\n","    tavily_search = TavilySearch(\n","        max_results=5,\n","        topic=\"general\",\n","    )\n","\n","    # --- Set up LLM (OpenAI chat model) ---\n","    llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.2)\n","    tools = [tavily_search]\n","\n","\n","    # --- Build a prompt / system instruction for the agent ---\n","    system_prompt = f\"\"\"\n","    You are an AI job-search assistant. Use the tool 'tavily_search' to search LinkedIn, Naukri and Monster job listings.\n","    Given the user's aspirational role text, create 1-2 suitable site:linkedin.com/jobs search queries,\n","    call the tavily_search tool with those queries across LinkedIn, Naukri and Monster, then produce a numbered list of the top 5 matching jobs with a higher matching score.\n","    Higher Matching Score Calculation: Compare against the required job description and skillsets required with the job listings against the current skills provided by the user. More the matching score, more the relevance.\n","    Return ONLY the numbered list (1..5) with Job Title, Company, Location, URL, Matching_Score, Matching rationale, One-liner summary of the key essence of the role requirement.\n","    While providing the output sort them according to the matching score in descending order.\n","    \"\"\"\n","\n","    # --- Create the agent ---\n","    # create_agent signature may vary; many versions accept llm=llm, tools=[...], system_prompt=...\n","    agent_executor = create_agent(model=llm, tools=tools, system_prompt=system_prompt)\n","\n","\n","    result = agent_executor.invoke({\n","        \"messages\": [\n","            {\"role\": \"user\", \"content\": f\"User's Aspirational Role: {aspirations}; User's Current Experiences: {current_skills}\"}\n","        ]\n","    })\n","    return result[\"messages\"][-1].content\n","\n","\n","def extract_text_from_file(uploaded_file) -> str:\n","    if uploaded_file is None:\n","        return \"\"\n","\n","    name = uploaded_file.name.lower()\n","    file_bytes = uploaded_file.read()\n","\n","    if name.endswith(\".docx\"):\n","        with NamedTemporaryFile(delete=False, suffix=\".docx\") as tmp:\n","            tmp.write(file_bytes)\n","            tmp_path = tmp.name\n","        doc = Document(tmp_path)\n","        text = \"\\n\".join(p.text for p in doc.paragraphs)\n","        os.remove(tmp_path)\n","        return text\n","    else:\n","        raise ValueError(\"Unsupported file type. Use .docx only\")\n","\n","\n"],"metadata":{"id":"jvmULMiwQ6LH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765461633751,"user_tz":-330,"elapsed":7,"user":{"displayName":"Benz Paul","userId":"09389317512058025402"}},"outputId":"b7a605fc-73d6-43d7-fc64-0b4e93e510a9"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting jobseeker_utils.py\n"]}]},{"cell_type":"code","source":["aspirational_role = \"Tech Co-Founder in Bangalore\"\n","current_skills = \"\"\"Certified AI & Data Science Leader with over 20 years of industry experience and a strong passion for teaching and\n","mentoring professionals in the domains of Generative AI, Agentic AI, Machine Learning and Data Science. Recognized for designing enterprise-grade\n","Gen AI, Agentic AI, AI/ML solutions and leading global analytics teams across compliance, risk, and data innovation domain.Currently working as\n","Risk Analytics Manager / Transformation Lead at Honeywell, architecting Gen AI-driven compliance frameworks. Adept at conducting workshops and\n","building AI literacy among business and technical teams.\"\"\"\n","\n","result = TopMatchingJobs(aspirational_role, current_skills)\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UOfeo9maozze","outputId":"e2e15ed9-6f14-4edb-c3d4-f461e739d201","executionInfo":{"status":"ok","timestamp":1765457557371,"user_tz":-330,"elapsed":14874,"user":{"displayName":"Benz Paul","userId":"09389317512058025402"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["1. Job Title: AI & ML Engineering Lead / Co-Founder  \n","   Company: Datafoundry  \n","   Location: Bangalore, Hyderabad & Vizag  \n","   URL: https://am.linkedin.com/company/datafoundryai  \n","   Matching_Score: 0.995  \n","   Matching rationale: Strong match with AI, ML, compliance, risk analytics, and leadership in Bangalore; experience with scalable AI systems and compliance frameworks aligns well.  \n","   One-liner summary: Lead AI-driven engineering and product development focusing on compliance and risk analytics in a high-growth AI startup environment.\n","\n","2. Job Title: CEO & Co-Founder  \n","   Company: rampp.ai  \n","   Location: Bangalore, Karnataka, India  \n","   URL: https://in.linkedin.com/in/ajay-agrawal-97573a3  \n","   Matching_Score: 0.630  \n","   Matching rationale: Relevant entrepreneurial role in AI/GenAI domain in Bangalore; leadership and startup experience align with aspirational role.  \n","   One-liner summary: Lead and scale an AI startup focused on enterprise transformation and generative AI solutions.\n","\n","3. Job Title: Founder / Co-Founder - AI & ML  \n","   Company: Datavedam  \n","   Location: Bangalore, Karnataka, India  \n","   URL: https://in.linkedin.com/in/deepakukr  \n","   Matching_Score: 0.479  \n","   Matching rationale: Co-founder role with AI/ML leadership in Bangalore; experience in LLM fine-tuning and AI innovation relevant to user's skills.  \n","   One-liner summary: Lead AI/ML innovation and startup growth focusing on advanced AI models and enterprise solutions.\n","\n","4. Job Title: Generative AI Engineer / Founder  \n","   Company: Konnect-AI  \n","   Location: Bangalore, Karnataka, India  \n","   URL: https://in.linkedin.com/in/lakshaykumar-tech  \n","   Matching_Score: 0.725  \n","   Matching rationale: Founder and GenAI engineer role with strong focus on generative AI and data science in Bangalore; aligns with user's expertise in Gen AI and leadership.  \n","   One-liner summary: Build and lead generative AI solutions and community initiatives in a startup environment.\n","\n","5. Job Title: AI & ML Product Leadership / Startup Founder  \n","   Company: Matters.AI  \n","   Location: Bangalore, Karnataka, India  \n","   URL: https://www.linkedin.com/company/mattersai  \n","   Matching_Score: 0.993  \n","   Matching rationale: AI startup focused on compliance, risk, and data security in Bangalore; aligns with user's risk analytics and AI leadership experience.  \n","   One-liner summary: Lead AI-driven compliance and risk management product development in a cybersecurity startup.\n"]}]},{"cell_type":"code","source":["## Check in the files in the GitHub Repository\n","%pwd\n","\n","!git config --global user.email \"benzp2@gmail.com\"\n","!git config --global user.name \"benzp\"\n","!git status\n","#!git add jobseeker_utils.py app.py JobSeekerAgent.ipynb\n","\n","!git commit -m \"Added new files into the repository\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lQIOjVBswH9S","executionInfo":{"status":"ok","timestamp":1765462548095,"user_tz":-330,"elapsed":1531,"user":{"displayName":"Benz Paul","userId":"09389317512058025402"}},"outputId":"ee45d3b5-fbfe-4ede-f670-f7447ba4c0aa"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes to be committed:\n","  (use \"git restore --staged <file>...\" to unstage)\n","\t\u001b[32mnew file:   JobSeekerAgent.ipynb\u001b[m\n","\t\u001b[32mnew file:   app.py\u001b[m\n","\t\u001b[32mnew file:   jobseeker_utils.py\u001b[m\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   JobSeekerAgent.ipynb\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31m__pycache__/\u001b[m\n","\n","[main 6601414] Added new files into the repository\n"," 3 files changed, 117 insertions(+)\n"," create mode 100644 JobSeekerAgent.ipynb\n"," create mode 100644 app.py\n"," create mode 100644 jobseeker_utils.py\n"]}]},{"cell_type":"code","source":["import langchain, sys\n","print(\"langchain:\", langchain.__version__)\n","import pkgutil\n","print(\"langchain.agents available members:\")\n","print([m.name for m in pkgutil.iter_modules(langchain.agents.__path__)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdoGLpnxSgRM","outputId":"920801b1-ac77-4062-b10b-25b01bbe396b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["langchain: 1.1.2\n","langchain.agents available members:\n","['factory', 'middleware', 'structured_output']\n"]}]}]}